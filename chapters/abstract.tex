\chapter*{Abstract}

%aj refer to the objectives that i mentioned on teams. use them to make an abstract. include link to git with video of collision with and without lidar-radar fusion

%video preformed poorly in git here is the youtube link: https://youtu.be/M2RLsMUXg3k
%longer video: https://youtu.be/qm5VrnFCw_g

%Autonomous vehicle find its application in wide variety of scenario. Some application areas include - self driving car, ware house automation, logistics, search and rescue operations to name a few. In addition, to meet the strict conditions for safer collision, there are multitude of sensors of different modality is used in perception. In this thesis we propose method to fuse lidar and radar towards safer autonomous navigation.  Lidar gives far and wide field perception while radar is capable to give near and narrow field perception. Exploiting the complementary capabilities of individual sensors, in this thesis we present a method to fuse lidar-radar data to achieve a holistic view of surrounding. Further we implement end-to-end navigational stack from sensing to perception to planning and navigation towards safer with collision avoidance navigation. Finally, backed by the experimental verification, we demonstrate that integrating radar with lidar helps to perceive the smaller objects in nearer field and avoid collision which would be ignored by lidar.

%This is what I would propose. Please parapharase it. Yes do not delete the original text that I wrote. I might need it later

Autonomous vehicles finds its applications in wide variety of scenarios, like search and rescue operations, warehouse automation to logistics and self-driving cars. Different perception modalities is employed to ensure safer collision avoidance. This thesis describes a method where lidar and radar is fused to increase the safety surrounding autonomous navigation. By combining the strength of the two sensor modalities, we present a method that leverages radar's narrow and near-field perception with lidar's wide and far-field perception. This produces a broad view of the vehicle's surroundings. Additionally, an end-to-end navigational stack incorporating sensing, perception, planning, and navigation was implemented, with the goal of collision free navigation. Lastly, supported by the results of experiments, we demonstrate the successfulness of lidar-radar fusion in detection of close laying smaller objects and avoiding collision that may occur with lidar alone. A video summarising the results of this work can be seen at YouTube: \url{https://youtu.be/M2RLsMUXg3k} or GitHub: \url{https://github.com/didriknr/Master-thesis-Didrik-Robsrud/blob/main/appendices/Abstract.mp4}